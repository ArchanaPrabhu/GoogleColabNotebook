{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AnomalyDetection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTggasKfDEFi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f6f976b1-fa92-4a5c-eacb-c291b8bf2512"
      },
      "source": [
        "!ls\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "!python TrainingAnomalyDetector_public.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Demo_GUI.py\t\t     sample_data\n",
            "Evaluate_Anomaly_Detector.m  Save_C3DFeatures_32Segments.m\n",
            "model.json\t\t     Temporal_Anomaly_Annotation.txt\n",
            "Plot_All_ROC.m\t\t     Test_Anomaly_Detector_public.py\n",
            "read_binary_blob.m\t     TrainingAnomalyDetector_public.py\n",
            "README.md\t\t     weights_L1L2.mat\n",
            "  File \"TrainingAnomalyDetector_public.py\", line 310\n",
            "    print \"These iteration=\" + str(total_iterations) + \") took: \" + str(datetime.now() - time_before) + \", with loss of \" + str(batch_loss)\n",
            "                           ^\n",
            "SyntaxError: invalid syntax\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNJyAKl0FqWs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "94e5fd51-c346-42a4-c12d-2d69334d17d7"
      },
      "source": [
        "!python -c 'import keras; print(keras.__version__)'\n",
        "!python -c 'from keras.layers import TimeDistributedDense'\n",
        "import os\n",
        "os.environ['KERAS_BACKEND'] = 'theano'\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation ,LSTM,Reshape\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import SGD,adam, Adagrad\n",
        "from scipy.io import loadmat, savemat\n",
        "from keras.models import model_from_json\n",
        "import theano.tensor as T\n",
        "import theano\n",
        "import csv\n",
        "import ConfigParser\n",
        "import collections\n",
        "import time\n",
        "import csv\n",
        "from os import listdir\n",
        "import skimage.transform\n",
        "from skimage import color\n",
        "from os.path import isfile, join\n",
        "import numpy as np\n",
        "import numpy\n",
        "from datetime import datetime\n",
        "import path\n",
        "from os.path import basename\n",
        "import glob\n",
        "import theano.sandbox\n",
        "theano.sandbox.cuda.use('gpu0')\n",
        "\n",
        "\n",
        "print(\"Create Model\")\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=4096,init='glorot_normal',W_regularizer=l2(0.001),activation='relu'))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(32,init='glorot_normal',W_regularizer=l2(0.001)))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(1,init='glorot_normal',W_regularizer=l2(0.001),activation='sigmoid'))\n",
        "\n",
        "\n",
        "def load_model(json_path): # Function to load the model\n",
        "    model = model_from_json(open(json_path).read())\n",
        "    return model\n",
        "\n",
        "def load_weights(model, weight_path): # Function to load the model weights\n",
        "    dict2 = loadmat(weight_path)\n",
        "    dict = conv_dict(dict2)\n",
        "    i = 0\n",
        "    for layer in model.layers:\n",
        "        weights = dict[str(i)]\n",
        "        layer.set_weights(weights)\n",
        "        i += 1\n",
        "    return model\n",
        "\n",
        "def conv_dict(dict2):\n",
        "    i = 0\n",
        "    dict = {}\n",
        "    for i in range(len(dict2)):\n",
        "        if str(i) in dict2:\n",
        "            if dict2[str(i)].shape == (0, 0):\n",
        "                dict[str(i)] = dict2[str(i)]\n",
        "            else:\n",
        "                weights = dict2[str(i)][0]\n",
        "                weights2 = []\n",
        "                for weight in weights:\n",
        "                    if weight.shape in [(1, x) for x in range(0, 5000)]:\n",
        "                        weights2.append(weight[0])\n",
        "                    else:\n",
        "                        weights2.append(weight)\n",
        "                dict[str(i)] = weights2\n",
        "    return dict\n",
        "\n",
        "def save_model(model, json_path, weight_path): # Function to save the model\n",
        "    json_string = model.to_json()\n",
        "    open(json_path, 'w').write(json_string)\n",
        "    dict = {}\n",
        "    i = 0\n",
        "    for layer in model.layers:\n",
        "        weights = layer.get_weights()\n",
        "        my_list = np.zeros(len(weights), dtype=np.object)\n",
        "        my_list[:] = weights\n",
        "        dict[str(i)] = my_list\n",
        "        i += 1\n",
        "    savemat(weight_path, dict)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load Training Dataset\n",
        "\n",
        "def load_dataset_Train_batch(AbnormalPath, NormalPath):\n",
        "#    print(\"Loading training batch\")\n",
        "\n",
        "    batchsize=60       # Each batch contain 60 videos.\n",
        "    n_exp=batchsize/2  # Number of abnormal and normal videos\n",
        "\n",
        "    Num_abnormal = 810  # Total number of abnormal videos in Training Dataset.\n",
        "    Num_Normal = 800    # Total number of Normal videos in Training Dataset.\n",
        "\n",
        "\n",
        "    # We assume the features of abnormal videos and normal videos are located in two different folders.\n",
        "    Abnor_list_iter = np.random.permutation(Num_abnormal)\n",
        "    Abnor_list_iter = Abnor_list_iter[Num_abnormal-n_exp:] # Indexes for randomly selected Abnormal Videos\n",
        "    Norm_list_iter = np.random.permutation(Num_Normal)\n",
        "    Norm_list_iter = Norm_list_iter[Num_Normal-n_exp:]     # Indexes for randomly selected Normal Videos\n",
        "\n",
        "\n",
        "    AllVideos_Path = AbnormalPath\n",
        "    def listdir_nohidden(AllVideos_Path):  # To ignore hidden files\n",
        "        file_dir_extension = os.path.join(AllVideos_Path, '*_C.txt')\n",
        "        for f in glob.glob(file_dir_extension):\n",
        "            if not f.startswith('.'):\n",
        "                yield os.path.basename(f)\n",
        "\n",
        "    All_Videos=sorted(listdir_nohidden(AllVideos_Path))\n",
        "    All_Videos.sort()\n",
        "    AllFeatures = []  # To store C3D features of a batch\n",
        "    print(\"Loading Abnormal videos Features...\")\n",
        "\n",
        "    Video_count=-1\n",
        "    for iv in Abnor_list_iter:\n",
        "        Video_count=Video_count+1\n",
        "        VideoPath = os.path.join(AllVideos_Path, All_Videos[iv])\n",
        "        f = open(VideoPath, \"r\")\n",
        "        words = f.read().split()\n",
        "        num_feat = len(words) / 4096\n",
        "        # Number of features per video to be loaded. In our case num_feat=32, as we divide the video into 32 segments. Note that\n",
        "        # we have already computed C3D features for the whole video and divide the video features into 32 segments. Please see Save_C3DFeatures_32Segments.m as well\n",
        "\n",
        "        count = -1;\n",
        "        VideoFeatues = []\n",
        "        for feat in xrange(0, num_feat):\n",
        "            feat_row1 = np.float32(words[feat * 4096:feat * 4096 + 4096])\n",
        "            count = count + 1\n",
        "            if count == 0:\n",
        "                VideoFeatues = feat_row1\n",
        "            if count > 0:\n",
        "                VideoFeatues = np.vstack((VideoFeatues, feat_row1))\n",
        "\n",
        "        if Video_count == 0:\n",
        "            AllFeatures = VideoFeatues\n",
        "        if Video_count > 0:\n",
        "            AllFeatures = np.vstack((AllFeatures, VideoFeatues))\n",
        "        print(\" Abnormal Features  loaded\")\n",
        "\n",
        "        \n",
        "        \n",
        "    print(\"Loading Normal videos...\")\n",
        "    AllVideos_Path =  NormalPath\n",
        "\n",
        "    def listdir_nohidden(AllVideos_Path):  # To ignore hidden files\n",
        "        file_dir_extension = os.path.join(AllVideos_Path, '*_C.txt')\n",
        "        for f in glob.glob(file_dir_extension):\n",
        "            if not f.startswith('.'):\n",
        "                yield os.path.basename(f)\n",
        "\n",
        "    All_Videos = sorted(listdir_nohidden(AllVideos_Path))\n",
        "    All_Videos.sort()\n",
        "\n",
        "    for iv in Norm_list_iter:\n",
        "        VideoPath = os.path.join(AllVideos_Path, All_Videos[iv])\n",
        "        f = open(VideoPath, \"r\")\n",
        "        words = f.read().split()\n",
        "        feat_row1 = np.array([])\n",
        "        num_feat = len(words) /4096   # Number of features to be loaded. In our case num_feat=32, as we divide the video into 32 segments.\n",
        "\n",
        "        count = -1;\n",
        "        VideoFeatues = []\n",
        "        for feat in xrange(0, num_feat):\n",
        "\n",
        "\n",
        "            feat_row1 = np.float32(words[feat * 4096:feat * 4096 + 4096])\n",
        "            count = count + 1\n",
        "            if count == 0:\n",
        "                VideoFeatues = feat_row1\n",
        "            if count > 0:\n",
        "                VideoFeatues = np.vstack((VideoFeatues, feat_row1))\n",
        "            feat_row1 = []\n",
        "        AllFeatures = np.vstack((AllFeatures, VideoFeatues))\n",
        "\n",
        "    print(\"Features  loaded\")\n",
        "\n",
        "\n",
        "    AllLabels = np.zeros(32*batchsize, dtype='uint8')\n",
        "    th_loop1=n_exp*32\n",
        "    th_loop2=n_exp*32-1\n",
        "\n",
        "\n",
        "\n",
        "    for iv in xrange(0, 32*batchsize):\n",
        "            if iv< th_loop1:\n",
        "                AllLabels[iv] = int(0)  # All instances of abnormal videos are labeled 0.  This will be used in custom_objective to keep track of normal and abnormal videos indexes.\n",
        "            if iv > th_loop2:\n",
        "                AllLabels[iv] = int(1)   # All instances of Normal videos are labeled 1. This will be used in custom_objective to keep track of normal and abnormal videos indexes.\n",
        "           # print(\"ALLabels  loaded\")\n",
        "\n",
        "    return  AllFeatures,AllLabels\n",
        "\n",
        "\n",
        "def custom_objective(y_true, y_pred):\n",
        "    'Custom Objective function'\n",
        "\n",
        "    y_true = T.flatten(y_true)\n",
        "    y_pred = T.flatten(y_pred)\n",
        "\n",
        "    n_seg = 32  # Because we have 32 segments per video.\n",
        "    nvid = 60\n",
        "    n_exp = nvid / 2\n",
        "    Num_d=32*nvid\n",
        "\n",
        "\n",
        "    sub_max = T.ones_like(y_pred) # sub_max represents the highest scoring instants in bags (videos).\n",
        "    sub_sum_labels = T.ones_like(y_true) # It is used to sum the labels in order to distinguish between normal and abnormal videos.\n",
        "    sub_sum_l1=T.ones_like(y_true)  # For holding the concatenation of summation of scores in the bag.\n",
        "    sub_l2 = T.ones_like(y_true) # For holding the concatenation of L2 of score in the bag.\n",
        "\n",
        "    for ii in xrange(0, nvid, 1):\n",
        "        # For Labels\n",
        "        mm = y_true[ii * n_seg:ii * n_seg + n_seg]\n",
        "        sub_sum_labels = T.concatenate([sub_sum_labels, T.stack(T.sum(mm))])  # Just to keep track of abnormal and normal vidoes\n",
        "\n",
        "        # For Features scores\n",
        "        Feat_Score = y_pred[ii * n_seg:ii * n_seg + n_seg]\n",
        "        sub_max = T.concatenate([sub_max, T.stack(T.max(Feat_Score))])         # Keep the maximum score of scores of all instances in a Bag (video)\n",
        "        sub_sum_l1 = T.concatenate([sub_sum_l1, T.stack(T.sum(Feat_Score))])   # Keep the sum of scores of all instances in a Bag (video)\n",
        "\n",
        "        z1 = T.ones_like(Feat_Score)\n",
        "        z2 = T.concatenate([z1, Feat_Score])\n",
        "        z3 = T.concatenate([Feat_Score, z1])\n",
        "        z_22 = z2[31:]\n",
        "        z_44 = z3[:33]\n",
        "        z = z_22 - z_44\n",
        "        z = z[1:32]\n",
        "        z = T.sum(T.sqr(z))\n",
        "        sub_l2 = T.concatenate([sub_l2, T.stack(z)])\n",
        "\n",
        "\n",
        "    # sub_max[Num_d:] means include all elements after Num_d.\n",
        "    # AllLabels =[2 , 4, 3 ,9 ,6 ,12,7 ,18 ,9 ,14]\n",
        "    # z=x[4:]\n",
        "    #[  6.  12.   7.  18.   9.  14.]\n",
        "\n",
        "    sub_score = sub_max[Num_d:]  # We need this step since we have used T.ones_like\n",
        "    F_labels = sub_sum_labels[Num_d:] # We need this step since we have used T.ones_like\n",
        "    #  F_labels contains integer 32 for normal video and 0 for abnormal videos. This because of labeling done at the end of \"load_dataset_Train_batch\"\n",
        "\n",
        "\n",
        "\n",
        "    # AllLabels =[2 , 4, 3 ,9 ,6 ,12,7 ,18 ,9 ,14]\n",
        "    # z=x[:4]\n",
        "    # [ 2 4 3 9]... This shows 0 to 3 elements\n",
        "\n",
        "    sub_sum_l1 = sub_sum_l1[Num_d:] # We need this step since we have used T.ones_like\n",
        "    sub_sum_l1 = sub_sum_l1[:n_exp]\n",
        "    sub_l2 = sub_l2[Num_d:]         # We need this step since we have used T.ones_like\n",
        "    sub_l2 = sub_l2[:n_exp]\n",
        "\n",
        "\n",
        "    indx_nor = theano.tensor.eq(F_labels, 32).nonzero()[0]  # Index of normal videos: Since we labeled 1 for each of 32 segments of normal videos F_labels=32 for normal video\n",
        "    indx_abn = theano.tensor.eq(F_labels, 0).nonzero()[0]\n",
        "\n",
        "    n_Nor=n_exp\n",
        "\n",
        "    Sub_Nor = sub_score[indx_nor] # Maximum Score for each of abnormal video\n",
        "    Sub_Abn = sub_score[indx_abn] # Maximum Score for each of normal video\n",
        "\n",
        "    z = T.ones_like(y_true)\n",
        "    for ii in xrange(0, n_Nor, 1):\n",
        "        sub_z = T.maximum(1 - Sub_Abn + Sub_Nor[ii], 0)\n",
        "        z = T.concatenate([z, T.stack(T.sum(sub_z))])\n",
        "\n",
        "    z = z[Num_d:]  # We need this step since we have used T.ones_like\n",
        "    z = T.mean(z, axis=-1) +  0.00008*T.sum(sub_sum_l1) + 0.00008*T.sum(sub_l2)  # Final Loss f\n",
        "\n",
        "    return z\n",
        "\n",
        "\n",
        "adagrad=Adagrad(lr=0.01, epsilon=1e-08)\n",
        "\n",
        "model.compile(loss=custom_objective, optimizer=adagrad)\n",
        "\n",
        "print(\"Starting training...\")\n",
        "\n",
        "AllClassPath='/newdata/UCF_Anomaly_Dataset/Dataset/CVPR_Data/C3D_Features_Txt/Train/'\n",
        "# AllClassPath contains C3D features (.txt file)  of each video. Each text file contains 32 features, each of 4096 dimension\n",
        "output_dir='/newdata/UCF_Anomaly_Dataset/Dataset/CVPR_Data/Trained_Models/TrainedModel_MIL_C3D/'\n",
        "# Output_dir is the directory where you want to save trained weights\n",
        "weights_path = output_dir + 'weights.mat'\n",
        "# weights.mat are the model weights that you will get after (or during) that training\n",
        "model_path = output_dir + 'model.json'\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "       os.makedirs(output_dir)\n",
        "\n",
        "All_class_files= listdir(AllClassPath)\n",
        "All_class_files.sort()\n",
        "loss_graph =[]\n",
        "num_iters = 20000\n",
        "total_iterations = 0\n",
        "batchsize=60\n",
        "time_before = datetime.now()\n",
        "\n",
        "for it_num in range(num_iters):\n",
        "\n",
        "    AbnormalPath = os.path.join(AllClassPath, All_class_files[0])  # Path of abnormal already computed C3D features\n",
        "    NormalPath = os.path.join(AllClassPath, All_class_files[1])    # Path of Normal already computed C3D features\n",
        "    inputs, targets=load_dataset_Train_batch(AbnormalPath, NormalPath)  # Load normal and abnormal video C3D features\n",
        "    batch_loss =model.train_on_batch(inputs, targets)\n",
        "    loss_graph = np.hstack((loss_graph, batch_loss))\n",
        "    total_iterations += 1\n",
        "    if total_iterations % 20 == 1:\n",
        "        print(\"These iteration=\" + str(total_iterations) + \") took: \" + str(datetime.now() - time_before) + \", with loss of \" + str(batch_loss))\n",
        "        iteration_path = output_dir + 'Iterations_graph_' + str(total_iterations) + '.mat'\n",
        "        savemat(iteration_path, dict(loss_graph=loss_graph))\n",
        "    if total_iterations % 1000 == 0:  # Save the model at every 1000th iterations.\n",
        "       weights_path = output_dir + 'weightsAnomalyL1L2_' + str(total_iterations) + '.mat'\n",
        "       save_model(model, model_path, weights_path)\n",
        "\n",
        "\n",
        "save_model(model, model_path, weights_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using Theano backend.\n",
            "1.1.0\n",
            "Using Theano backend.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ff151b7e842d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mConfigParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ConfigParser'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6uBuJUqKKgf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "dcdb5038-09d2-4ecc-e2b8-55e79e50d652"
      },
      "source": [
        "!ls\n",
        "import os\n",
        "os.environ['KERAS_BACKEND'] = 'theano'\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import SGD ,Adagrad\n",
        "from scipy.io import loadmat, savemat\n",
        "from keras.models import model_from_json\n",
        "import theano.tensor as T\n",
        "import theano\n",
        "import csv\n",
        "import configparser\n",
        "import collections\n",
        "import time\n",
        "import csv\n",
        "from math import factorial\n",
        "\n",
        "from os import listdir\n",
        "import skimage.transform\n",
        "from skimage import color\n",
        "from os.path import isfile, join\n",
        "import numpy as np\n",
        "import numpy\n",
        "from datetime import datetime\n",
        "from scipy.spatial.distance import cdist,pdist,squareform\n",
        "import theano.sandbox\n",
        "#import c3D_model\n",
        "#import Initialization_function\n",
        "#from moviepy.editor import VideoFileClip\n",
        "#from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os, sys\n",
        "import pickle\n",
        "from PyQt5 import QtWidgets   # If PyQt4 is not working in your case, you can try PyQt5, \n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "def load_model(json_path):\n",
        "    model = model_from_json(open(json_path).read())\n",
        "    return model\n",
        "\n",
        "def load_weights(model, weight_path):\n",
        "    dict2 = loadmat(weight_path)\n",
        "    dict = conv_dict(dict2)\n",
        "    i = 0\n",
        "    for layer in model.layers:\n",
        "        weights = dict[str(i)]\n",
        "        layer.set_weights(weights)\n",
        "        i += 1\n",
        "    return model\n",
        "\n",
        "def conv_dict(dict2): # Helper function to save the model\n",
        "    i = 0\n",
        "    dict = {}\n",
        "    for i in range(len(dict2)):\n",
        "        if str(i) in dict2:\n",
        "            if dict2[str(i)].shape == (0, 0):\n",
        "                dict[str(i)] = dict2[str(i)]\n",
        "            else:\n",
        "                weights = dict2[str(i)][0]\n",
        "                weights2 = []\n",
        "                for weight in weights:\n",
        "                    if weight.shape in [(1, x) for x in range(0, 5000)]:\n",
        "                        weights2.append(weight[0])\n",
        "                    else:\n",
        "                        weights2.append(weight)\n",
        "                dict[str(i)] = weights2\n",
        "    return dict\n",
        "\n",
        "\n",
        "def savitzky_golay(y, window_size, order, deriv=0, rate=1):\n",
        "    #try:\n",
        "    window_size = np.abs(np.int(window_size))\n",
        "    order = np.abs(np.int(order))\n",
        "    #except ValueError, msg:\n",
        "    #    raise ValueError(\"window_size and order have to be of type int\")\n",
        "\n",
        "    if window_size % 2 != 1 or window_size < 1:\n",
        "        raise TypeError(\"window_size size must be a positive odd number\")\n",
        "\n",
        "    if window_size < order + 2:\n",
        "        raise TypeError(\"window_size is too small for the polynomials order\")\n",
        "\n",
        "    order_range = range(order + 1)\n",
        "\n",
        "    half_window = (window_size - 1) // 2\n",
        "    b = np.mat([[k ** i for i in order_range] for k in range(-half_window, half_window + 1)])\n",
        "    m = np.linalg.pinv(b).A[deriv] * rate ** deriv * factorial(deriv)\n",
        "    firstvals = y[0] - np.abs(y[1:half_window + 1][::-1] - y[0])\n",
        "    lastvals = y[-1] + np.abs(y[-half_window - 1:-1][::-1] - y[-1])\n",
        "    y = np.concatenate((firstvals, y, lastvals))\n",
        "    return np.convolve(m[::-1], y,mode='valid')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load Video\n",
        "\n",
        "def load_dataset_One_Video_Features(Test_Video_Path):\n",
        "\n",
        "    VideoPath =Test_Video_Path\n",
        "    f = open(VideoPath, \"r\")\n",
        "    words = f.read().split()\n",
        "    num_feat = len(words) / 4096\n",
        "    # Number of features per video to be loaded. In our case num_feat=32, as we divide the video into 32 segments. Npte that\n",
        "    # we have already computed C3D features for the whole video and divide the video features into 32 segments.\n",
        "\n",
        "    count = -1;\n",
        "    VideoFeatues = []\n",
        "    for feat in range(0, int(num_feat)):\n",
        "        feat_row1 = np.float32(words[feat * 4096:feat * 4096 + 4096])\n",
        "        count = count + 1\n",
        "        if count == 0:\n",
        "            VideoFeatues = feat_row1\n",
        "        if count > 0:\n",
        "            VideoFeatues = np.vstack((VideoFeatues, feat_row1))\n",
        "    AllFeatures = VideoFeatues\n",
        "\n",
        "    return  AllFeatures\n",
        "\n",
        "class PrettyWidget(QtWidgets.QWidget):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(PrettyWidget, self).__init__()\n",
        "        self.initUI()\n",
        "\n",
        "    def initUI(self):\n",
        "        self.setGeometry(500, 100, 500, 500)\n",
        "        self.setWindowTitle('Anomaly Detection')\n",
        "        btn = QtWidgets.QPushButton('ANOMALY DETECTION SYSTEM \\n Please select video', self)\n",
        "\n",
        "        \n",
        "        weights_path = 'weights_L1L2.mat'\n",
        "        model_path = 'model.json'\n",
        "        ########################################\n",
        "        ######    LOAD ABNORMALITY MODEL   ######\n",
        "        global model\n",
        "        model = load_model(model_path)\n",
        "        load_weights(model, weights_path)\n",
        "\n",
        "        #####   LOAD C3D Pre-Trained Network #####\n",
        "       # global score_function\n",
        "       # score_function = Initialization_function.get_prediction_function()\n",
        "\n",
        "\n",
        "\n",
        "        btn.resize(btn.sizeHint())\n",
        "        btn.clicked.connect(self.SingleBrowse)\n",
        "        btn.move(150, 200)\n",
        "        self.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def SingleBrowse(self):\n",
        "        video_path = QtWidgets.QFileDialog.getOpenFileName(self,\n",
        "                                                        'Single File',\n",
        "                                                        \"/home/cvlab/Waqas_Data/Anomaly_Data/Normal_test_abn\")\n",
        "\n",
        "        print(video_path)\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        #Total_frames = cap.get(cv2.CV_CAP_PROP_FRAME_COUNT)\n",
        "        print(cv2)\n",
        "        Total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "        total_segments = np.linspace(1, Total_frames, num=33)\n",
        "        total_segments = total_segments.round()\n",
        "        FeaturePath=(video_path)\n",
        "        FeaturePath = FeaturePath[0:-4]\n",
        "        FeaturePath = FeaturePath+ '.txt'\n",
        "        inputs = load_dataset_One_Video_Features(FeaturePath)\n",
        "        #inputs = np.reshape(inputs, (32, 4096))\n",
        "        predictions = model.predict_on_batch(inputs)\n",
        "\n",
        "        Frames_Score = []\n",
        "        count = -1;\n",
        "        for iv in range(0, 32):\n",
        "            F_Score = np.matlib.repmat(predictions[iv],1,(int(total_segments[iv+1])-int(total_segments[iv])))\n",
        "            count = count + 1\n",
        "            if count == 0:\n",
        "              Frames_Score = F_Score\n",
        "            if count > 0:\n",
        "              Frames_Score = np.hstack((Frames_Score, F_Score))\n",
        "\n",
        "\n",
        "\n",
        "        cap = cv2.VideoCapture((video_path))\n",
        "        while not cap.isOpened():\n",
        "            cap = cv2.VideoCapture((video_path))\n",
        "            cv2.waitKey(1000)\n",
        "            print (\"Wait for the header\")\n",
        "\n",
        "        pos_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
        "        Total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "\n",
        "        print (\"Anomaly Prediction\")\n",
        "        x = np.linspace(1, Total_frames, Total_frames)\n",
        "        scores = Frames_Score\n",
        "        scores1=scores.reshape((scores.shape[1],))\n",
        "        scores1 = savitzky_golay(scores1, 101, 3)\n",
        "        plt.close()\n",
        "        break_pt=min(scores1.shape[0], x.shape[0])\n",
        "        plt.axis([0, Total_frames, 0, 1])\n",
        "        i=0;\n",
        "        while True:\n",
        "            flag, frame = cap.read()\n",
        "            if flag:\n",
        "                i = i + 1\n",
        "                cv2.imshow('video', frame)\n",
        "                jj=i%25\n",
        "                if jj==1:\n",
        "                    plt.plot(x[:i], scores1[:i], color='r', linewidth=3)\n",
        "                    plt.draw()\n",
        "                    plt.pause(0.000000000000000000000001)\n",
        "\n",
        "                pos_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
        "                print (str(pos_frame) + \" frames\")\n",
        "            else:\n",
        "                # The next frame is not ready, so we try to read it again\n",
        "                cap.set(cv2.CAP_PROP_POS_FRAMES, pos_frame - 1)\n",
        "                print(\"frame is not ready\")\n",
        "                # It is better to wait for a while for the next frame to be ready\n",
        "                cv2.waitKey(1000)\n",
        "\n",
        "            if cv2.waitKey(10) == 27:\n",
        "                break\n",
        "            if cap.get(cv2.CAP_PROP_POS_FRAMES)== break_pt:\n",
        "                #cap.get(cv2.CAP_PROP_FRAME_COUNT):\n",
        "                # If the number of captured frames is equal to the total number of frames,\n",
        "                # we stop\n",
        "                break\n",
        "\n",
        "\n",
        "def main():\n",
        "    app = QtWidgets.QApplication(sys.argv)\n",
        "    w = PrettyWidget()\n",
        "    app.exec_()\n",
        "\n",
        "\n",
        "main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Demo_GUI.py\t\t     sample_data\n",
            "Evaluate_Anomaly_Detector.m  Save_C3DFeatures_32Segments.m\n",
            "model.json\t\t     Temporal_Anomaly_Annotation.txt\n",
            "Plot_All_ROC.m\t\t     Test_Anomaly_Detector_public.py\n",
            "read_binary_blob.m\t     TrainingAnomalyDetector_public.py\n",
            "README.md\t\t     weights_L1L2.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using Theano backend.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}